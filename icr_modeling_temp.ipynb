{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import umap\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, log_loss, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import ClusterCentroids, RandomUnderSampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv('icr-identify-age-related-conditions/train.csv')\n",
    "test_df = pd.read_csv('icr-identify-age-related-conditions/test.csv')\n",
    "greeks_df = pd.read_csv('icr-identify-age-related-conditions/greeks.csv')\n",
    "\n",
    "# join greeks and add Epsilon\n",
    "train_df = pd.merge(train_df, greeks_df, on = 'Id')\n",
    "train_df = train_df.drop(['EJ', 'Alpha', 'Beta', 'Gamma', 'Delta'], axis = 1)\n",
    "train_df['Epsilon'] = train_df['Epsilon'].replace('Unknown', np.nan)\n",
    "\n",
    "# dropping rows with missing values in Epsilon as it helps with class imbalance\n",
    "# if future data does have this column, it will be important to know if it is missing\n",
    "train_df = train_df[train_df['Epsilon'].isna() == False].copy()\n",
    "train_df['Epsilon'] = pd.to_datetime(train_df['Epsilon'])\n",
    "\n",
    "# change epsilon to months since 1-1-2019 when data started to pick up\n",
    "train_df['Months Since 1-1-2019'] = (train_df['Epsilon'] - pd.to_datetime('2019-01-01')).dt.days // 30\n",
    "train_df = train_df.drop('Epsilon', axis = 1)\n",
    "train_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot styles\n",
    "font_dict_header = {'size': 20, 'weight': 'bold'}\n",
    "font_dict_axistitle = {'size': 14, 'weight': 'bold'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# pre-process data\n",
    "y = train_df['Class']\n",
    "x = train_df.drop(['Id', 'Class'], axis = 1, inplace = False)\n",
    "\n",
    "# create x and y train\n",
    "X_train = x.copy()\n",
    "y_train = y.copy()\n",
    "\n",
    "# scale and impute data\n",
    "X_train_columns = X_train.columns\n",
    "X_train_index = X_train.index\n",
    "standard_scaler = StandardScaler()\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "knn_imputer = KNNImputer()\n",
    "X_train = knn_imputer.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = X_train_columns, index = X_train_index)\n",
    "\n",
    "# dimension reduction features\n",
    "umap_n = 3\n",
    "umap_reducer = umap.UMAP(n_components = umap_n, random_state = random_seed)\n",
    "umap_columns = ['Component ' + str(i + 1) for i in range(umap_n)]\n",
    "umap_components = umap_reducer.fit_transform(X_train)\n",
    "umap_df = pd.DataFrame(data = umap_components, columns = umap_columns, index = X_train_index)\n",
    "X_train = pd.concat([X_train, umap_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit knn models for later\n",
    "knn_cols = [\n",
    "    'Component 1', 'Component 2', 'Component 3'\n",
    "]\n",
    "\n",
    "# save models is a dictionary\n",
    "knn_models_list = [5, 7, 11]\n",
    "knn_models_dict = {}\n",
    "for n in knn_models_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors = n)\n",
    "    knn.fit(X_train[knn_cols], y_train)\n",
    "    knn_models_dict[n] = knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each row and predict using knn\n",
    "knn_train_df = X_train[knn_cols]\n",
    "knn_train_df['Class'] = y_train\n",
    "knn_target = 'Class'\n",
    "\n",
    "knn_predictions = {}\n",
    "for n in knn_models_list:\n",
    "    knn_predictions[n] = []\n",
    "    \n",
    "for i in range(len(knn_train_df)):\n",
    "    row_train = knn_train_df.drop(i)\n",
    "    row = knn_train_df.loc[i].to_frame().T\n",
    "    \n",
    "    row_y = row_train[knn_target]\n",
    "    row_train = row_train.drop([knn_target], axis = 1)\n",
    "    row = row.drop([knn_target], axis = 1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    row_train = scaler.fit_transform(row_train)\n",
    "    row = scaler.transform(row)\n",
    "    \n",
    "    for n in knn_models_list:\n",
    "        knn = KNeighborsClassifier(n_neighbors = n)\n",
    "        knn.fit(row_train, row_y)\n",
    "        knn_predictions[n].append(knn.predict_proba(row)[0][1])\n",
    "\n",
    "for n in knn_models_list:\n",
    "    col_name = 'knn_' + str(n)\n",
    "    X_train[col_name] = np.array(knn_predictions[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (473, 62)\n",
      "Shape of y: (473,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X:', X_train.shape)\n",
    "print('Shape of y:', y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(y_true, x, model):\n",
    "    pred = model.predict(x)\n",
    "    pred_proba = model.predict_proba(x)[:, 1]\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true, pred_proba)\n",
    "    accuracy = accuracy_score(y_true, pred)\n",
    "    precision = precision_score(y_true, pred)\n",
    "    recall = recall_score(y_true, pred)\n",
    "    f1 = f1_score(y_true, pred)\n",
    "    \n",
    "    print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "    return roc_auc, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbors(df, row, n_neighbors):\n",
    "    if row > len(df):\n",
    "        raise ValueError('Row index is greater than the number of rows in the dataframe.')\n",
    "    \n",
    "    if row < 0:\n",
    "        raise ValueError('Row index is less than 0.')\n",
    "    \n",
    "    knn_df = df.drop('Class', axis = 1)\n",
    "    knn_columns = knn_df.columns\n",
    "    knn_index = knn_df.index\n",
    "    knn_df = StandardScaler().fit_transform(knn_df)\n",
    "    knn_df = pd.DataFrame(knn_df, columns = knn_columns, index = knn_index)\n",
    "    knn = NearestNeighbors(n_neighbors = n_neighbors).fit(knn_df)\n",
    "    \n",
    "    distances, indices = knn.kneighbors(knn_df.loc[row, :].values.reshape(1, -1))\n",
    "    \n",
    "    distances = np.array(distances)\n",
    "    neighbors = distances.argsort()[:n_neighbors]\n",
    "    \n",
    "    return df.iloc[indices[0], :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-38 {color: black;background-color: white;}#sk-container-id-38 pre{padding: 0;}#sk-container-id-38 div.sk-toggleable {background-color: white;}#sk-container-id-38 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-38 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-38 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-38 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-38 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-38 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-38 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-38 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-38 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-38 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-38 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-38 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-38 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-38 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-38 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-38 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-38 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-38 div.sk-item {position: relative;z-index: 1;}#sk-container-id-38 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-38 div.sk-item::before, #sk-container-id-38 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-38 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-38 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-38 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-38 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-38 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-38 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-38 div.sk-label-container {text-align: center;}#sk-container-id-38 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-38 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-38\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.2, min_samples_leaf=4,\n",
       "                           min_samples_split=4, n_estimators=500,\n",
       "                           random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" checked><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.2, min_samples_leaf=4,\n",
       "                           min_samples_split=4, n_estimators=500,\n",
       "                           random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, min_samples_leaf=4,\n",
       "                           min_samples_split=4, n_estimators=500,\n",
       "                           random_state=42)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(random_seed)\n",
    "gb = GradientBoostingClassifier(random_state = random_seed)\n",
    "\n",
    "parameters = {\n",
    "    'loss': ['log_loss'],\n",
    "    'learning_rate': [0.2],\n",
    "    'n_estimators': [500],\n",
    "    'criterion': ['friedman_mse'],\n",
    "    'max_depth': [3],\n",
    "    'min_samples_leaf': [4],\n",
    "    'min_samples_split': [4],\n",
    "    'max_features': [None]\n",
    "}\n",
    "\n",
    "grid_obj = GridSearchCV(gb, parameters, scoring = 'roc_auc', cv = 5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "gb = grid_obj.best_estimator_\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>...</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.138626</td>\n",
       "      <td>0.047299</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.2</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>0.978207</td>\n",
       "      <td>0.936488</td>\n",
       "      <td>0.932752</td>\n",
       "      <td>0.956295</td>\n",
       "      <td>0.949119</td>\n",
       "      <td>0.950572</td>\n",
       "      <td>0.016214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.138626      0.047299         0.001968        0.000038   \n",
       "\n",
       "  param_criterion param_learning_rate param_loss param_max_depth  \\\n",
       "0    friedman_mse                 0.2   log_loss               3   \n",
       "\n",
       "  param_max_features param_min_samples_leaf  ... param_n_estimators  \\\n",
       "0               None                      4  ...                500   \n",
       "\n",
       "                                              params split0_test_score  \\\n",
       "0  {'criterion': 'friedman_mse', 'learning_rate':...          0.978207   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.936488           0.932752           0.956295           0.949119   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.950572        0.016214                1  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view results of grid search\n",
    "gb_results = pd.DataFrame(grid_obj.cv_results_)\n",
    "gb_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.9506\n"
     ]
    }
   ],
   "source": [
    "# print results of roc auc score\n",
    "print('ROC AUC Score:', np.round(gb_results['mean_test_score'].max(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pandas series with features importances and sort it\n",
    "importances = pd.Series(gb.feature_importances_, index = X_train.columns).sort_values(ascending = True)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize = (10, 20))\n",
    "plt.title('Feature Importances', fontdict = font_dict_header)\n",
    "plt.box(False)\n",
    "plt.barh(importances.index, importances.values)\n",
    "plt.xlabel('Importance Score', fontdict = font_dict_axistitle)\n",
    "plt.ylabel('Features', fontdict = font_dict_axistitle)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TabPFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-39 {color: black;background-color: white;}#sk-container-id-39 pre{padding: 0;}#sk-container-id-39 div.sk-toggleable {background-color: white;}#sk-container-id-39 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-39 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-39 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-39 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-39 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-39 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-39 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-39 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-39 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-39 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-39 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-39 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-39 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-39 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-39 div.sk-item {position: relative;z-index: 1;}#sk-container-id-39 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-39 div.sk-item::before, #sk-container-id-39 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-39 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-39 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-39 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-39 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-39 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-39 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-39 div.sk-label-container {text-align: center;}#sk-container-id-39 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-39 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-39\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TabPFNClassifier(N_ensemble_configurations=10, seed=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" checked><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TabPFNClassifier</label><div class=\"sk-toggleable__content\"><pre>TabPFNClassifier(N_ensemble_configurations=10, seed=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TabPFNClassifier(N_ensemble_configurations=10, seed=42)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(random_seed)\n",
    "tpfn = TabPFNClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'N_ensemble_configurations': [10],\n",
    "    'batch_size_inference': [32],\n",
    "    'device': ['cpu'],\n",
    "    'multiclass_decoder': ['permutation'],\n",
    "    'seed': [random_seed]\n",
    "}\n",
    "\n",
    "grid_obj = GridSearchCV(tpfn, parameters, scoring = 'roc_auc', cv = 5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "tpfn = grid_obj.best_estimator_\n",
    "tpfn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_N_ensemble_configurations</th>\n",
       "      <th>param_batch_size_inference</th>\n",
       "      <th>param_device</th>\n",
       "      <th>param_multiclass_decoder</th>\n",
       "      <th>param_seed</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.754238</td>\n",
       "      <td>0.014921</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>cpu</td>\n",
       "      <td>permutation</td>\n",
       "      <td>42</td>\n",
       "      <td>{'N_ensemble_configurations': 10, 'batch_size_...</td>\n",
       "      <td>0.978829</td>\n",
       "      <td>0.970735</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.942596</td>\n",
       "      <td>0.940639</td>\n",
       "      <td>0.948378</td>\n",
       "      <td>0.024754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001167      0.000062         0.754238        0.014921   \n",
       "\n",
       "  param_N_ensemble_configurations param_batch_size_inference param_device  \\\n",
       "0                              10                         32          cpu   \n",
       "\n",
       "  param_multiclass_decoder param_seed  \\\n",
       "0              permutation         42   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'N_ensemble_configurations': 10, 'batch_size_...           0.978829   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.970735           0.909091           0.942596           0.940639   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.948378        0.024754                1  "
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view results of grid search\n",
    "tpfn_results = pd.DataFrame(grid_obj.cv_results_)\n",
    "tpfn_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.9484\n"
     ]
    }
   ],
   "source": [
    "# print results of roc auc score\n",
    "print('ROC AUC Score:', np.round(tpfn_results['mean_test_score'].max(), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-40 {color: black;background-color: white;}#sk-container-id-40 pre{padding: 0;}#sk-container-id-40 div.sk-toggleable {background-color: white;}#sk-container-id-40 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-40 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-40 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-40 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-40 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-40 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-40 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-40 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-40 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-40 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-40 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-40 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-40 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-40 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-40 div.sk-item {position: relative;z-index: 1;}#sk-container-id-40 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-40 div.sk-item::before, #sk-container-id-40 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-40 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-40 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-40 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-40 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-40 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-40 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-40 div.sk-label-container {text-align: center;}#sk-container-id-40 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-40 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-40\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, cache_size=10000, gamma=0.01, probability=True, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" checked><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, cache_size=10000, gamma=0.01, probability=True, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, cache_size=10000, gamma=0.01, probability=True, random_state=42)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(random_seed)\n",
    "svm = SVC(random_state = random_seed, probability=True)\n",
    "\n",
    "parameters = {\n",
    "    'kernel': ['rbf'],\n",
    "    'C': [10],\n",
    "    'gamma': [0.01],\n",
    "    'random_state': [random_seed],\n",
    "    'probability': [True],\n",
    "    'cache_size': [10000],\n",
    "}\n",
    "\n",
    "grid_obj = GridSearchCV(svm, parameters, scoring = 'roc_auc', cv = 5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "svm = grid_obj.best_estimator_\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_cache_size</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_probability</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019729</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>{'C': 10, 'cache_size': 10000, 'gamma': 0.01, ...</td>\n",
       "      <td>0.965131</td>\n",
       "      <td>0.968244</td>\n",
       "      <td>0.907223</td>\n",
       "      <td>0.902805</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.932242</td>\n",
       "      <td>0.028561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.019729      0.001301         0.003046         0.00049      10   \n",
       "\n",
       "  param_cache_size param_gamma param_kernel param_probability  \\\n",
       "0            10000        0.01          rbf              True   \n",
       "\n",
       "  param_random_state                                             params  \\\n",
       "0                 42  {'C': 10, 'cache_size': 10000, 'gamma': 0.01, ...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.965131           0.968244           0.907223           0.902805   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.917808         0.932242        0.028561                1  "
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view results of grid search\n",
    "svm_results = pd.DataFrame(grid_obj.cv_results_)\n",
    "svm_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.9322\n"
     ]
    }
   ],
   "source": [
    "# print results of roc auc score\n",
    "print('ROC AUC Score:', np.round(svm_results['mean_test_score'].max(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cross_validation(X, y, models, model_names, n_splits = 5):\n",
    "    skf = StratifiedKFold(n_splits = n_splits, random_state = random_seed, shuffle = True)\n",
    "    \n",
    "    # create dataframe to hold results\n",
    "    results_df = pd.DataFrame(columns = ['Model', 'Fold', 'Accuracy', 'ROC_AUC'])\n",
    "    \n",
    "    for sampling_strategy in ['None', 'SMOTE', 'RandomOverSampler']:\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "            X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "            if sampling_strategy == 'SMOTE':\n",
    "                X_train, y_train = SMOTE(random_state = random_seed).fit_resample(X_train, y_train)\n",
    "            elif sampling_strategy == 'RandomOverSampler':\n",
    "                X_train, y_train = RandomOverSampler(random_state = random_seed).fit_resample(X_train, y_train)\n",
    "            elif sampling_strategy == 'RandomUnderSampler':\n",
    "                X_train, y_train = RandomUnderSampler(random_state = random_seed).fit_resample(X_train, y_train)\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        \n",
    "            for model, model_name in zip(models, model_names):\n",
    "                if sampling_strategy == 'None':\n",
    "                    model_name = model_name\n",
    "                else:\n",
    "                    model_name = model_name + ' with ' + sampling_strategy\n",
    "                \n",
    "                print(model_name, 'Fold', i + 1)\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                y_proba = model.predict_proba(X_test)[:, 1]\n",
    "                \n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                roc_auc = roc_auc_score(y_test, y_proba)\n",
    "                \n",
    "                new_result_index = len(results_df)\n",
    "                new_results_row = pd.DataFrame({\n",
    "                    'Model': model_name, \n",
    "                    'Fold': i + 1, \n",
    "                    'Accuracy': accuracy, \n",
    "                    'ROC_AUC': roc_auc\n",
    "                }, index = [new_result_index])\n",
    "                \n",
    "                results_df = pd.concat([results_df, new_results_row])\n",
    "            \n",
    "            # average predictions\n",
    "            avg_pred = np.mean([model.predict_proba(X_test)[:, 1] for model in models], axis = 0)\n",
    "            \n",
    "            avg_accuracy = accuracy_score(y_test, np.round(avg_pred))\n",
    "            avg_roc_auc = roc_auc_score(y_test, avg_pred)\n",
    "            \n",
    "            new_result_index = len(results_df)\n",
    "            if sampling_strategy == 'None':\n",
    "                model_name = 'Average'\n",
    "            else:\n",
    "                model_name = 'Average' + ' with ' + sampling_strategy\n",
    "            new_results_row = pd.DataFrame({\n",
    "                'Model': model_name, \n",
    "                'Fold': i + 1, \n",
    "                'Accuracy': avg_accuracy, \n",
    "                'ROC_AUC': avg_roc_auc\n",
    "            }, index = [new_result_index])\n",
    "        \n",
    "            results_df = pd.concat([results_df, new_results_row])\n",
    "            print()\n",
    "        \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingClassifier(learning_rate = 0.2, min_samples_leaf = 4,min_samples_split = 4, n_estimators = 500, random_state = random_seed)\n",
    "tpfn_model = TabPFNClassifier(N_ensemble_configurations = 10, seed = random_seed)\n",
    "svm_model = SVC(C = 10, gamma = 0.01, probability = True, random_state = random_seed)\n",
    "\n",
    "models = [gb_model, tpfn_model]\n",
    "model_names = ['Gradient Boosting', 'TabPFN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Fold 1\n",
      "TabPFN Fold 1\n",
      "\n",
      "Gradient Boosting Fold 2\n",
      "TabPFN Fold 2\n",
      "\n",
      "Gradient Boosting Fold 3\n",
      "TabPFN Fold 3\n",
      "\n",
      "Gradient Boosting Fold 4\n",
      "TabPFN Fold 4\n",
      "\n",
      "Gradient Boosting Fold 5\n",
      "TabPFN Fold 5\n",
      "\n",
      "Gradient Boosting with SMOTE Fold 1\n",
      "TabPFN with SMOTE Fold 1\n",
      "\n",
      "Gradient Boosting with SMOTE Fold 2\n",
      "TabPFN with SMOTE Fold 2\n",
      "\n",
      "Gradient Boosting with SMOTE Fold 3\n",
      "TabPFN with SMOTE Fold 3\n",
      "\n",
      "Gradient Boosting with SMOTE Fold 4\n",
      "TabPFN with SMOTE Fold 4\n",
      "\n",
      "Gradient Boosting with SMOTE Fold 5\n",
      "TabPFN with SMOTE Fold 5\n",
      "\n",
      "Gradient Boosting with RandomOverSampler Fold 1\n",
      "TabPFN with RandomOverSampler Fold 1\n",
      "\n",
      "Gradient Boosting with RandomOverSampler Fold 2\n",
      "TabPFN with RandomOverSampler Fold 2\n",
      "\n",
      "Gradient Boosting with RandomOverSampler Fold 3\n",
      "TabPFN with RandomOverSampler Fold 3\n",
      "\n",
      "Gradient Boosting with RandomOverSampler Fold 4\n",
      "TabPFN with RandomOverSampler Fold 4\n",
      "\n",
      "Gradient Boosting with RandomOverSampler Fold 5\n",
      "TabPFN with RandomOverSampler Fold 5\n",
      "\n",
      "Gradient Boosting with RandomUnderSampler Fold 1\n",
      "TabPFN with RandomUnderSampler Fold 1\n",
      "\n",
      "Gradient Boosting with RandomUnderSampler Fold 2\n",
      "TabPFN with RandomUnderSampler Fold 2\n",
      "\n",
      "Gradient Boosting with RandomUnderSampler Fold 3\n",
      "TabPFN with RandomUnderSampler Fold 3\n",
      "\n",
      "Gradient Boosting with RandomUnderSampler Fold 4\n",
      "TabPFN with RandomUnderSampler Fold 4\n",
      "\n",
      "Gradient Boosting with RandomUnderSampler Fold 5\n",
      "TabPFN with RandomUnderSampler Fold 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_results = model_cross_validation(X_train, y_train, models, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cv_results.drop('Fold', axis = 1).groupby('Model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Accuracy Z Score</th>\n",
       "      <th>ROC AUC Z Score</th>\n",
       "      <th>Average Z Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average with SMOTE</th>\n",
       "      <td>0.936529</td>\n",
       "      <td>0.959776</td>\n",
       "      <td>1.107921</td>\n",
       "      <td>1.186692</td>\n",
       "      <td>1.147307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting with SMOTE</th>\n",
       "      <td>0.928018</td>\n",
       "      <td>0.961952</td>\n",
       "      <td>0.753585</td>\n",
       "      <td>1.477537</td>\n",
       "      <td>1.115561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting with RandomOverSampler</th>\n",
       "      <td>0.930213</td>\n",
       "      <td>0.960232</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>1.247714</td>\n",
       "      <td>1.046340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average with RandomOverSampler</th>\n",
       "      <td>0.930190</td>\n",
       "      <td>0.954694</td>\n",
       "      <td>0.844034</td>\n",
       "      <td>0.507526</td>\n",
       "      <td>0.675780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabPFN with SMOTE</th>\n",
       "      <td>0.921769</td>\n",
       "      <td>0.951818</td>\n",
       "      <td>0.493428</td>\n",
       "      <td>0.123167</td>\n",
       "      <td>0.308297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.917536</td>\n",
       "      <td>0.950246</td>\n",
       "      <td>0.317193</td>\n",
       "      <td>-0.086844</td>\n",
       "      <td>0.115174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabPFN with RandomOverSampler</th>\n",
       "      <td>0.913326</td>\n",
       "      <td>0.950667</td>\n",
       "      <td>0.141890</td>\n",
       "      <td>-0.030577</td>\n",
       "      <td>0.055656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.909071</td>\n",
       "      <td>0.949973</td>\n",
       "      <td>-0.035278</td>\n",
       "      <td>-0.123299</td>\n",
       "      <td>-0.079288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabPFN</th>\n",
       "      <td>0.915431</td>\n",
       "      <td>0.947079</td>\n",
       "      <td>0.229541</td>\n",
       "      <td>-0.510035</td>\n",
       "      <td>-0.140247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average with RandomUnderSampler</th>\n",
       "      <td>0.873012</td>\n",
       "      <td>0.944014</td>\n",
       "      <td>-1.536544</td>\n",
       "      <td>-0.919754</td>\n",
       "      <td>-1.228149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting with RandomUnderSampler</th>\n",
       "      <td>0.873035</td>\n",
       "      <td>0.943166</td>\n",
       "      <td>-1.535611</td>\n",
       "      <td>-1.033080</td>\n",
       "      <td>-1.284346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabPFN with RandomUnderSampler</th>\n",
       "      <td>0.870885</td>\n",
       "      <td>0.937135</td>\n",
       "      <td>-1.625128</td>\n",
       "      <td>-1.839045</td>\n",
       "      <td>-1.732087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Accuracy   ROC_AUC  \\\n",
       "Model                                                           \n",
       "Average with SMOTE                         0.936529  0.959776   \n",
       "Gradient Boosting with SMOTE               0.928018  0.961952   \n",
       "Gradient Boosting with RandomOverSampler   0.930213  0.960232   \n",
       "Average with RandomOverSampler             0.930190  0.954694   \n",
       "TabPFN with SMOTE                          0.921769  0.951818   \n",
       "Average                                    0.917536  0.950246   \n",
       "TabPFN with RandomOverSampler              0.913326  0.950667   \n",
       "Gradient Boosting                          0.909071  0.949973   \n",
       "TabPFN                                     0.915431  0.947079   \n",
       "Average with RandomUnderSampler            0.873012  0.944014   \n",
       "Gradient Boosting with RandomUnderSampler  0.873035  0.943166   \n",
       "TabPFN with RandomUnderSampler             0.870885  0.937135   \n",
       "\n",
       "                                           Accuracy Z Score  ROC AUC Z Score  \\\n",
       "Model                                                                          \n",
       "Average with SMOTE                                 1.107921         1.186692   \n",
       "Gradient Boosting with SMOTE                       0.753585         1.477537   \n",
       "Gradient Boosting with RandomOverSampler           0.844967         1.247714   \n",
       "Average with RandomOverSampler                     0.844034         0.507526   \n",
       "TabPFN with SMOTE                                  0.493428         0.123167   \n",
       "Average                                            0.317193        -0.086844   \n",
       "TabPFN with RandomOverSampler                      0.141890        -0.030577   \n",
       "Gradient Boosting                                 -0.035278        -0.123299   \n",
       "TabPFN                                             0.229541        -0.510035   \n",
       "Average with RandomUnderSampler                   -1.536544        -0.919754   \n",
       "Gradient Boosting with RandomUnderSampler         -1.535611        -1.033080   \n",
       "TabPFN with RandomUnderSampler                    -1.625128        -1.839045   \n",
       "\n",
       "                                           Average Z Score  \n",
       "Model                                                       \n",
       "Average with SMOTE                                1.147307  \n",
       "Gradient Boosting with SMOTE                      1.115561  \n",
       "Gradient Boosting with RandomOverSampler          1.046340  \n",
       "Average with RandomOverSampler                    0.675780  \n",
       "TabPFN with SMOTE                                 0.308297  \n",
       "Average                                           0.115174  \n",
       "TabPFN with RandomOverSampler                     0.055656  \n",
       "Gradient Boosting                                -0.079288  \n",
       "TabPFN                                           -0.140247  \n",
       "Average with RandomUnderSampler                  -1.228149  \n",
       "Gradient Boosting with RandomUnderSampler        -1.284346  \n",
       "TabPFN with RandomUnderSampler                   -1.732087  "
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Accuracy Z Score'] = (results['Accuracy'] - results['Accuracy'].mean()) / results['Accuracy'].std()\n",
    "results['ROC AUC Z Score'] = (results['ROC_AUC'] - results['ROC_AUC'].mean()) / results['ROC_AUC'].std()\n",
    "results['Average Z Score'] = results[['Accuracy Z Score', 'ROC AUC Z Score']].mean(axis = 1)\n",
    "results.sort_values('Average Z Score', ascending = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-41 {color: black;background-color: white;}#sk-container-id-41 pre{padding: 0;}#sk-container-id-41 div.sk-toggleable {background-color: white;}#sk-container-id-41 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-41 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-41 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-41 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-41 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-41 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-41 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-41 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-41 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-41 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-41 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-41 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-41 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-41 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-41 div.sk-item {position: relative;z-index: 1;}#sk-container-id-41 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-41 div.sk-item::before, #sk-container-id-41 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-41 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-41 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-41 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-41 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-41 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-41 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-41 div.sk-label-container {text-align: center;}#sk-container-id-41 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-41 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-41\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.2, min_samples_leaf=4,\n",
       "                           min_samples_split=4, n_estimators=500,\n",
       "                           random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" checked><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.2, min_samples_leaf=4,\n",
       "                           min_samples_split=4, n_estimators=500,\n",
       "                           random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, min_samples_leaf=4,\n",
       "                           min_samples_split=4, n_estimators=500,\n",
       "                           random_state=42)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>...</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Months Since 1-1-2019</th>\n",
       "      <th>Component 1</th>\n",
       "      <th>Component 2</th>\n",
       "      <th>Component 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.558848</td>\n",
       "      <td>-0.236450</td>\n",
       "      <td>-0.269977</td>\n",
       "      <td>-0.246707</td>\n",
       "      <td>-0.218848</td>\n",
       "      <td>-1.827988</td>\n",
       "      <td>-0.081263</td>\n",
       "      <td>-0.182438</td>\n",
       "      <td>-0.052735</td>\n",
       "      <td>-0.395860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.929947</td>\n",
       "      <td>-0.408672</td>\n",
       "      <td>-0.655369</td>\n",
       "      <td>-0.893790</td>\n",
       "      <td>0.503464</td>\n",
       "      <td>-0.760123</td>\n",
       "      <td>-0.434323</td>\n",
       "      <td>2.226851</td>\n",
       "      <td>11.619739</td>\n",
       "      <td>7.621610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.225481</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>-0.269977</td>\n",
       "      <td>-0.353351</td>\n",
       "      <td>-0.218848</td>\n",
       "      <td>-0.590782</td>\n",
       "      <td>-0.019649</td>\n",
       "      <td>-1.699753</td>\n",
       "      <td>1.248230</td>\n",
       "      <td>0.083465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442469</td>\n",
       "      <td>0.068401</td>\n",
       "      <td>-0.297474</td>\n",
       "      <td>1.432582</td>\n",
       "      <td>-0.426912</td>\n",
       "      <td>-0.762454</td>\n",
       "      <td>0.526775</td>\n",
       "      <td>2.932274</td>\n",
       "      <td>11.954643</td>\n",
       "      <td>7.493268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.558848</td>\n",
       "      <td>-0.434973</td>\n",
       "      <td>-0.269977</td>\n",
       "      <td>-0.424898</td>\n",
       "      <td>-0.218848</td>\n",
       "      <td>-0.563739</td>\n",
       "      <td>-0.081263</td>\n",
       "      <td>0.464433</td>\n",
       "      <td>-0.110995</td>\n",
       "      <td>-0.063489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087048</td>\n",
       "      <td>-0.408672</td>\n",
       "      <td>0.561687</td>\n",
       "      <td>-0.254382</td>\n",
       "      <td>0.855214</td>\n",
       "      <td>1.387027</td>\n",
       "      <td>0.126318</td>\n",
       "      <td>2.010786</td>\n",
       "      <td>14.731083</td>\n",
       "      <td>7.372338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.287987</td>\n",
       "      <td>-0.790047</td>\n",
       "      <td>-0.269977</td>\n",
       "      <td>-0.427010</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>-1.364881</td>\n",
       "      <td>-0.081263</td>\n",
       "      <td>-0.954510</td>\n",
       "      <td>-0.110995</td>\n",
       "      <td>0.077998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.301146</td>\n",
       "      <td>0.369209</td>\n",
       "      <td>-0.582443</td>\n",
       "      <td>0.310174</td>\n",
       "      <td>1.341820</td>\n",
       "      <td>-0.765550</td>\n",
       "      <td>-0.274140</td>\n",
       "      <td>1.598144</td>\n",
       "      <td>12.587306</td>\n",
       "      <td>7.499876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.442170</td>\n",
       "      <td>-1.098849</td>\n",
       "      <td>-0.269977</td>\n",
       "      <td>-0.262403</td>\n",
       "      <td>-0.218848</td>\n",
       "      <td>-0.191901</td>\n",
       "      <td>-0.081263</td>\n",
       "      <td>-0.277829</td>\n",
       "      <td>-0.110995</td>\n",
       "      <td>-0.122355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246584</td>\n",
       "      <td>-0.167971</td>\n",
       "      <td>0.407682</td>\n",
       "      <td>0.414445</td>\n",
       "      <td>-0.560983</td>\n",
       "      <td>-0.762822</td>\n",
       "      <td>-0.354231</td>\n",
       "      <td>3.288703</td>\n",
       "      <td>11.520083</td>\n",
       "      <td>7.336023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>-0.625522</td>\n",
       "      <td>-0.438413</td>\n",
       "      <td>-0.269977</td>\n",
       "      <td>-0.443861</td>\n",
       "      <td>-0.218848</td>\n",
       "      <td>-0.556978</td>\n",
       "      <td>-0.081263</td>\n",
       "      <td>-1.699753</td>\n",
       "      <td>-0.110995</td>\n",
       "      <td>0.391235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394169</td>\n",
       "      <td>0.717381</td>\n",
       "      <td>-0.163769</td>\n",
       "      <td>0.731915</td>\n",
       "      <td>-0.295406</td>\n",
       "      <td>1.387027</td>\n",
       "      <td>0.767050</td>\n",
       "      <td>1.966031</td>\n",
       "      <td>13.314116</td>\n",
       "      <td>8.447943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>-0.675527</td>\n",
       "      <td>-0.227986</td>\n",
       "      <td>0.071075</td>\n",
       "      <td>-0.412389</td>\n",
       "      <td>0.314057</td>\n",
       "      <td>-0.759799</td>\n",
       "      <td>0.027845</td>\n",
       "      <td>-0.482026</td>\n",
       "      <td>-0.089792</td>\n",
       "      <td>-0.386557</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.158033</td>\n",
       "      <td>0.529504</td>\n",
       "      <td>-0.320990</td>\n",
       "      <td>-0.643166</td>\n",
       "      <td>0.485644</td>\n",
       "      <td>1.387027</td>\n",
       "      <td>1.007324</td>\n",
       "      <td>1.442425</td>\n",
       "      <td>14.486184</td>\n",
       "      <td>7.480410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>-0.117137</td>\n",
       "      <td>0.710646</td>\n",
       "      <td>-0.269977</td>\n",
       "      <td>0.064023</td>\n",
       "      <td>0.636319</td>\n",
       "      <td>0.186698</td>\n",
       "      <td>-0.080621</td>\n",
       "      <td>0.482319</td>\n",
       "      <td>-0.076683</td>\n",
       "      <td>0.061129</td>\n",
       "      <td>...</td>\n",
       "      <td>1.431413</td>\n",
       "      <td>2.345951</td>\n",
       "      <td>-0.596009</td>\n",
       "      <td>-0.141918</td>\n",
       "      <td>2.026932</td>\n",
       "      <td>-0.757668</td>\n",
       "      <td>1.007324</td>\n",
       "      <td>1.335232</td>\n",
       "      <td>12.587315</td>\n",
       "      <td>8.486352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>-0.133805</td>\n",
       "      <td>-0.498048</td>\n",
       "      <td>0.127455</td>\n",
       "      <td>0.177279</td>\n",
       "      <td>-0.015074</td>\n",
       "      <td>0.984460</td>\n",
       "      <td>-0.081263</td>\n",
       "      <td>1.141114</td>\n",
       "      <td>-0.110995</td>\n",
       "      <td>0.131376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100788</td>\n",
       "      <td>-0.043327</td>\n",
       "      <td>-0.409977</td>\n",
       "      <td>-0.490482</td>\n",
       "      <td>1.881457</td>\n",
       "      <td>1.387027</td>\n",
       "      <td>-0.113957</td>\n",
       "      <td>2.220012</td>\n",
       "      <td>13.397289</td>\n",
       "      <td>8.500677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>-0.258818</td>\n",
       "      <td>-0.979272</td>\n",
       "      <td>-0.269977</td>\n",
       "      <td>-0.230095</td>\n",
       "      <td>-0.218848</td>\n",
       "      <td>0.950656</td>\n",
       "      <td>-0.081263</td>\n",
       "      <td>-0.723485</td>\n",
       "      <td>-0.110995</td>\n",
       "      <td>-0.278799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344650</td>\n",
       "      <td>-0.408672</td>\n",
       "      <td>-0.657480</td>\n",
       "      <td>-0.595499</td>\n",
       "      <td>-0.402179</td>\n",
       "      <td>-0.753809</td>\n",
       "      <td>-0.514414</td>\n",
       "      <td>2.905690</td>\n",
       "      <td>12.189433</td>\n",
       "      <td>6.794479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>473 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AB        AF        AH        AM        AR        AX        AY  \\\n",
       "0   -0.558848 -0.236450 -0.269977 -0.246707 -0.218848 -1.827988 -0.081263   \n",
       "1   -0.225481  0.014720 -0.269977 -0.353351 -0.218848 -0.590782 -0.019649   \n",
       "2   -0.558848 -0.434973 -0.269977 -0.424898 -0.218848 -0.563739 -0.081263   \n",
       "3   -0.287987 -0.790047 -0.269977 -0.427010  0.564196 -1.364881 -0.081263   \n",
       "4   -0.442170 -1.098849 -0.269977 -0.262403 -0.218848 -0.191901 -0.081263   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "468 -0.625522 -0.438413 -0.269977 -0.443861 -0.218848 -0.556978 -0.081263   \n",
       "469 -0.675527 -0.227986  0.071075 -0.412389  0.314057 -0.759799  0.027845   \n",
       "470 -0.117137  0.710646 -0.269977  0.064023  0.636319  0.186698 -0.080621   \n",
       "471 -0.133805 -0.498048  0.127455  0.177279 -0.015074  0.984460 -0.081263   \n",
       "472 -0.258818 -0.979272 -0.269977 -0.230095 -0.218848  0.950656 -0.081263   \n",
       "\n",
       "           AZ        BC       BD   ...        GB        GE        GF  \\\n",
       "0   -0.182438 -0.052735 -0.395860  ... -0.929947 -0.408672 -0.655369   \n",
       "1   -1.699753  1.248230  0.083465  ... -0.442469  0.068401 -0.297474   \n",
       "2    0.464433 -0.110995 -0.063489  ...  0.087048 -0.408672  0.561687   \n",
       "3   -0.954510 -0.110995  0.077998  ... -0.301146  0.369209 -0.582443   \n",
       "4   -0.277829 -0.110995 -0.122355  ... -0.246584 -0.167971  0.407682   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "468 -1.699753 -0.110995  0.391235  ... -0.394169  0.717381 -0.163769   \n",
       "469 -0.482026 -0.089792 -0.386557  ... -1.158033  0.529504 -0.320990   \n",
       "470  0.482319 -0.076683  0.061129  ...  1.431413  2.345951 -0.596009   \n",
       "471  1.141114 -0.110995  0.131376  ... -0.100788 -0.043327 -0.409977   \n",
       "472 -0.723485 -0.110995 -0.278799  ...  0.344650 -0.408672 -0.657480   \n",
       "\n",
       "           GH        GI        GL  Months Since 1-1-2019  Component 1  \\\n",
       "0   -0.893790  0.503464 -0.760123              -0.434323     2.226851   \n",
       "1    1.432582 -0.426912 -0.762454               0.526775     2.932274   \n",
       "2   -0.254382  0.855214  1.387027               0.126318     2.010786   \n",
       "3    0.310174  1.341820 -0.765550              -0.274140     1.598144   \n",
       "4    0.414445 -0.560983 -0.762822              -0.354231     3.288703   \n",
       "..        ...       ...       ...                    ...          ...   \n",
       "468  0.731915 -0.295406  1.387027               0.767050     1.966031   \n",
       "469 -0.643166  0.485644  1.387027               1.007324     1.442425   \n",
       "470 -0.141918  2.026932 -0.757668               1.007324     1.335232   \n",
       "471 -0.490482  1.881457  1.387027              -0.113957     2.220012   \n",
       "472 -0.595499 -0.402179 -0.753809              -0.514414     2.905690   \n",
       "\n",
       "     Component 2  Component 3  \n",
       "0      11.619739     7.621610  \n",
       "1      11.954643     7.493268  \n",
       "2      14.731083     7.372338  \n",
       "3      12.587306     7.499876  \n",
       "4      11.520083     7.336023  \n",
       "..           ...          ...  \n",
       "468    13.314116     8.447943  \n",
       "469    14.486184     7.480410  \n",
       "470    12.587315     8.486352  \n",
       "471    13.397289     8.500677  \n",
       "472    12.189433     6.794479  \n",
       "\n",
       "[473 rows x 59 columns]"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_pipeline(x):\n",
    "    x = x.select_dtypes(include = [np.number])\n",
    "    x['Months Since 1-1-2019'] = [X_train['Months Since 1-1-2019'].max() + 1] * len(x)\n",
    "    \n",
    "    X_columns = x.columns\n",
    "    X_index = x.index\n",
    "    \n",
    "    x = standard_scaler.transform(x)\n",
    "    x = knn_imputer.transform(x)\n",
    "    x = pd.DataFrame(x, columns = X_columns, index = X_index)\n",
    "    \n",
    "    umap_components = umap_reducer.transform(x)\n",
    "    umap_df = pd.DataFrame(data = umap_components, columns = umap_columns, index = X_index)\n",
    "    x = pd.concat([x, umap_df], axis = 1)\n",
    "    \n",
    "    for n in knn_models_list:\n",
    "        knn_predictions = knn_models_dict[n].predict_proba(x[knn_cols])[0][1]\n",
    "        x['knn_' + str(n)] = knn_predictions\n",
    "        \n",
    "    model_data, model_responce = SMOTE(random_state = random_seed).fit_resample(X_train, y_train)\n",
    "    gb_model.fit(model_data, model_responce)\n",
    "    tpfn_model.fit(model_data, model_responce)\n",
    "    \n",
    "    gb_prediction = gb_model.predict_proba(x)\n",
    "    tpfn_prediction = tpfn_model.predict_proba(x)\n",
    "    average_prediction = np.mean([gb_prediction, tpfn_prediction], axis = 0)\n",
    "    \n",
    "    x['class_0'] = average_prediction[:, 0]\n",
    "    x['class_1'] = average_prediction[:, 1]\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = prediction_pipeline(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_df[['Id']]\n",
    "predictions = X_test[['class_0', 'class_1']]\n",
    "submission_df = pd.concat([submission_df, predictions], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('/kaggle/working/submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apple_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
