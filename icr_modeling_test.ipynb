{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT first with internet option turned on\n",
    "# Use GPU env\n",
    "\n",
    "# !pip download tabpfn --no-deps -d pip-packages\n",
    "\n",
    "# from tabpfn import TabPFNClassifier\n",
    "# TabPFNClassifier(N_ensemble_configurations = 64, device = 'cuda:0')\n",
    "\n",
    "# !mv /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/prior_diff_real_checkpoint_n_0_epoch_100.cpkt pip-packages/\n",
    "# !zip -r pip-packages.zip pip-packages\n",
    "\n",
    "# now you need to download the zip and upload it as dataset with the plus in the top left\n",
    "# then you need to add it to the notebook as data on the right, and name it `pip-packages-icr`\n",
    "\n",
    "# now you can turn internet off and still install, like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyprojroot import here\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# import base estimators\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "local_dir = str(here()) + '/'\n",
    "kaggle_dir = '/kaggle/input/'\n",
    "train_df = pd.read_csv(local_dir + 'icr-identify-age-related-conditions/train.csv')\n",
    "test_df = pd.read_csv(local_dir + 'icr-identify-age-related-conditions/test.csv')\n",
    "greeks_df = pd.read_csv(local_dir + 'icr-identify-age-related-conditions/greeks.csv')\n",
    "\n",
    "# join greeks and add Epsilon\n",
    "train_df = pd.merge(train_df, greeks_df, on = 'Id')\n",
    "train_df = train_df.drop(['Beta', 'Gamma', 'Delta'], axis = 1)\n",
    "train_df['Epsilon'] = train_df['Epsilon'].replace('Unknown', np.nan)\n",
    "\n",
    "# dropping rows with missing values in Epsilon as it helps with class imbalance\n",
    "# if future data does have this column, it will be important to know if it is missing\n",
    "train_df = train_df[train_df['Epsilon'].isna() == False].copy()\n",
    "train_df['Epsilon'] = pd.to_datetime(train_df['Epsilon'])\n",
    "\n",
    "# change epsilon to months since 1-1-2019 when data started to pick up\n",
    "train_df['Days Since 1-1-2019'] = (train_df['Epsilon'] - pd.to_datetime('2019-01-01')).dt.days\n",
    "train_df = train_df.drop('Epsilon', axis = 1)\n",
    "train_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "random_seed = 101010\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# pre-process data\n",
    "y_alpha = train_df['Alpha']\n",
    "y_class = train_df['Class']\n",
    "x = train_df.drop(['Id', 'Alpha', 'Class'], axis = 1, inplace = False)\n",
    "\n",
    "# create x and y train\n",
    "X_train = x.copy()\n",
    "y_train_alpha = y_alpha.copy()\n",
    "# alpha_encoder = LabelEncoder()\n",
    "# y_train_alpha = alpha_encoder.fit_transform(y_train_alpha)\n",
    "y_train_class = y_class.copy()\n",
    "\n",
    "# scale and impute data\n",
    "X_train['EJ'].replace({'A': 0, 'B': 1}, inplace = True)\n",
    "X_train_columns = X_train.columns\n",
    "X_train_index = X_train.index\n",
    "standard_scaler = StandardScaler()\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "knn_imputer = KNNImputer()\n",
    "X_train = knn_imputer.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = X_train_columns, index = X_train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    def __init__(self):\n",
    "        self.classifiers =[\n",
    "            XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.85),\n",
    "            XGBClassifier(),\n",
    "            TabPFNClassifier(N_ensemble_configurations=24),\n",
    "            TabPFNClassifier(N_ensemble_configurations=64)\n",
    "        ]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y = y.values\n",
    "        unique_classes, y = np.unique(y, return_inverse=True)\n",
    "        self.classes_ = unique_classes\n",
    "        first_category = X.EJ.unique()[0]\n",
    "        X.EJ = X.EJ.eq(first_category).astype('int')\n",
    "        for classifier in self.classifiers:\n",
    "            if classifier==self.classifiers[2] or classifier==self.classifiers[3]:\n",
    "                classifier.fit(X,y,overwrite_warning =True)\n",
    "            else :\n",
    "                classifier.fit(X, y)\n",
    "     \n",
    "    def predict_proba(self, X):\n",
    "        probabilities = np.stack([classifier.predict_proba(X) for classifier in self.classifiers])\n",
    "        averaged_probabilities = np.mean(probabilities, axis=0)\n",
    "        class_0_est_instances = averaged_probabilities[:, 0].sum()\n",
    "        others_est_instances = averaged_probabilities[:, 1:].sum()\n",
    "        # Weighted probabilities based on class imbalance\n",
    "        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n",
    "        return new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import KFold as KF, GridSearchCV\n",
    "cv_outer = KF(n_splits = 10, shuffle=True, random_state=42)\n",
    "cv_inner = KF(n_splits = 5, shuffle=True, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # y_true: correct labels 0, 1\n",
    "    # y_pred: predicted probabilities of class=1\n",
    "    # calculate the number of observations for each class\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    # calculate the weights for each class to balance classes\n",
    "    w_0 = 1 / N_0\n",
    "    w_1 = 1 / N_1\n",
    "    # calculate the predicted probabilities for each class\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    # calculate the summed log loss for each class\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1))\n",
    "    # calculate the weighted summed logarithmic loss\n",
    "    # (factgor of 2 included to give same result as LL with balanced input)\n",
    "    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n",
    "    # return the average log loss\n",
    "    return balanced_log_loss/(N_0+N_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, x,y,y_meta):\n",
    "    outer_results = list()\n",
    "    best_loss = np.inf\n",
    "    split = 0\n",
    "    splits = 5\n",
    "    for train_idx,val_idx in tqdm(cv_inner.split(x), total = splits):\n",
    "        split+=1\n",
    "        x_train, x_val = x.iloc[train_idx],x.iloc[val_idx]\n",
    "        y_train, y_val = y_meta.iloc[train_idx], y.iloc[val_idx]\n",
    "                \n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict_proba(x_val)\n",
    "        probabilities = np.concatenate((y_pred[:,:1], np.sum(y_pred[:,1:], 1, keepdims=True)), axis=1)\n",
    "        p0 = probabilities[:,:1]\n",
    "        p0[p0 > 0.86] = 1\n",
    "        p0[p0 < 0.14] = 0\n",
    "        y_p = np.empty((y_pred.shape[0],))\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            if p0[i]>=0.5:\n",
    "                y_p[i]= False\n",
    "            else :\n",
    "                y_p[i]=True\n",
    "        y_p = y_p.astype(int)\n",
    "        loss = balanced_log_loss(y_val,y_p)\n",
    "\n",
    "        if loss<best_loss:\n",
    "            best_model = model\n",
    "            best_loss = loss\n",
    "            print('best_model_saved')\n",
    "        outer_results.append(loss)\n",
    "        print('>val_loss=%.5f, split = %.1f' % (loss,split))\n",
    "    print('LOSS: %.5f' % (np.mean(outer_results)))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      B\n",
       "1      D\n",
       "2      A\n",
       "3      A\n",
       "4      A\n",
       "      ..\n",
       "468    A\n",
       "469    A\n",
       "470    A\n",
       "471    A\n",
       "472    A\n",
       "Name: Alpha, Length: 473, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape\n",
      "Alpha\n",
      "A    365\n",
      "B     61\n",
      "G     29\n",
      "D     18\n",
      "Name: count, dtype: int64\n",
      "Resample dataset shape\n",
      "Alpha\n",
      "B    365\n",
      "D    365\n",
      "A    365\n",
      "G    365\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "train_ros, y_ros = ros.fit_resample(X_train, y_train_alpha)\n",
    "print('Original dataset shape')\n",
    "print(y_train_alpha.value_counts())\n",
    "print('Resample dataset shape')\n",
    "print(y_ros.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_ros = train_ros.copy()\n",
    "y_ = y_ros.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "yt = Ensemble()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21533ad5501a454cb2fb64081a609fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    172\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\roperator.py:15\u001b[0m, in \u001b[0;36mrsub\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrsub\u001b[39m(left, right):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m right \u001b[39m-\u001b[39;49m left\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m m \u001b[39m=\u001b[39m training(yt,x_ros,y_,y_ros)\n",
      "Cell \u001b[1;32mIn[40], line 24\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, x, y, y_meta)\u001b[0m\n\u001b[0;32m     22\u001b[0m         y_p[i]\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     23\u001b[0m y_p \u001b[39m=\u001b[39m y_p\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m loss \u001b[39m=\u001b[39m balanced_log_loss(y_val,y_p)\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m loss\u001b[39m<\u001b[39mbest_loss:\n\u001b[0;32m     27\u001b[0m     best_model \u001b[39m=\u001b[39m model\n",
      "Cell \u001b[1;32mIn[39], line 5\u001b[0m, in \u001b[0;36mbalanced_log_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbalanced_log_loss\u001b[39m(y_true, y_pred):\n\u001b[0;32m      2\u001b[0m     \u001b[39m# y_true: correct labels 0, 1\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[39m# y_pred: predicted probabilities of class=1\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[39m# calculate the number of observations for each class\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     N_0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m y_true)\n\u001b[0;32m      6\u001b[0m     N_1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(y_true)\n\u001b[0;32m      7\u001b[0m     \u001b[39m# calculate the weights for each class to balance classes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\arraylike.py:198\u001b[0m, in \u001b[0;36mOpsMixin.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__rsub__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__rsub__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, roperator\u001b[39m.\u001b[39;49mrsub)\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\series.py:6112\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[0;32m   6111\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[1;32m-> 6112\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\base.py:1348\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1345\u001b[0m rvalues \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1347\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1348\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1350\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(result, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:232\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    230\u001b[0m     \u001b[39m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:178\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    174\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    177\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m         result \u001b[39m=\u001b[39m _masked_arith_op(left, right, op)\n\u001b[0;32m    179\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:135\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    132\u001b[0m         mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(y \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mFalse\u001b[39;00m, mask)\n\u001b[0;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m--> 135\u001b[0m         result[mask] \u001b[39m=\u001b[39m op(xrav[mask], y)\n\u001b[0;32m    137\u001b[0m np\u001b[39m.\u001b[39mputmask(result, \u001b[39m~\u001b[39mmask, np\u001b[39m.\u001b[39mnan)\n\u001b[0;32m    138\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)  \u001b[39m# 2D compat\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\pandas\\core\\roperator.py:15\u001b[0m, in \u001b[0;36mrsub\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrsub\u001b[39m(left, right):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m right \u001b[39m-\u001b[39;49m left\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "m = training(yt,x_ros,y_,y_ros)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
